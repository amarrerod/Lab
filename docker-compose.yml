services:
  nginx:
    image: nginx:alpine
    container_name: nginx
    volumes:
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "80:80"
    depends_on:
      - jupyterhub
      - ollama
      - chat
    restart: unless-stopped

  jupyterhub:
    image: jupyterhub/jupyterhub
    container_name: jupyterhub
    volumes:
      - /etc/passwd:/etc/passwd:ro
      - /etc/group:/etc/group:ro
      - /etc/shadow:/etc/shadow:ro
      - /home:/home
      - ./jupyterhub:/srv/jupyterhub
    expose:
      - "8000"
    restart: unless-stopped
    user: root

  ollama:
    image: ollama/ollama
    container_name: ollama
    expose:
      - "11434"
    volumes:
      - ollama_data:/home/ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia
    restart: unless-stopped

  chat:
    image: ghcr.io/open-webui/open-webui:main
    container_name: chat
    environment:
      - OLLAMA_API_BASE_URL=http://ollama:11434
    expose:
      - "3000"
    depends_on:
      - ollama
    restart: unless-stopped

volumes:
  ollama_data:

networks:
  my-network-name:
    name: lab